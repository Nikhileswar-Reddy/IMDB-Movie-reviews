{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classifier: Movie Reviews\n",
    "\n",
    "#### Problem statement:\n",
    "* Sentiment analysis is one of the most widely studied and challenging problems to be solved. The agenda in sentiment analysis is classifying the polarity of a given text at the document, sentence or feature level. Here I am trying to find weather the expressed opinion in a movie review is **positive** or **negative**.\n",
    "\n",
    "#### Data:\n",
    "* Large Movie Review Database: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>pos</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neg</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train     test\n",
       "pos  12500.0  12500.0\n",
       "neg  12500.0  12500.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = pd.DataFrame()\n",
    "num_data.loc[\"pos\", \"train\"] = len(glob.glob(\"./aclImdb/train/pos/*.txt\"))\n",
    "num_data.loc[\"neg\", \"train\"] = len(glob.glob(\"./aclImdb/train/neg/*.txt\"))\n",
    "num_data.loc[\"pos\", \"test\"] = len(glob.glob(\"./aclImdb/test/pos/*.txt\"))\n",
    "num_data.loc[\"neg\", \"test\"] = len(glob.glob(\"./aclImdb/test/neg/*.txt\"))\n",
    "num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 50,000 records in the train and test data sets. Half are positive and half are negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyPrind (Python Progress Indicator)\n",
    "* ProgPercent(iterations, track_time=True, stream=2, title='', monitor=False, update_interval=None)\n",
    "* Initializes a progress bar object that allows visualization of an iterational computation in the standard output screen.\n",
    "* Iterations = Number of iterations for the iterative computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind\n",
    "\n",
    "#length = 50000\n",
    "pper = pyprind.ProgPercent(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for positive and negative\n",
    "labels = {\"pos\": 1, \"neg\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all the Positive and Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100 %] Time elapsed: 00:04:07 | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "\n",
    "for i in (\"train\", \"test\"):\n",
    "    for j in (\"pos\", \"neg\"):\n",
    "        path = \"./aclImdb/%s/%s/*.txt\" % (i, j)\n",
    "        for file in glob.glob(path)[0:12500]:\n",
    "            with open(file, \"r\", encoding=\"utf8\") as infile:\n",
    "                text = infile.read()\n",
    "            dataframe = dataframe.append([[text, labels[j]]], ignore_index=True)\n",
    "            pper.update()\n",
    "\n",
    "dataframe.columns = [\"review\", \"sentiment\"]\n",
    "len(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25001</td>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25002</td>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25003</td>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25004</td>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      Bromwell High is a cartoon comedy. It ran at t...          1\n",
       "1      Homelessness (or Houselessness as George Carli...          1\n",
       "2      Brilliant over-acting by Lesley Ann Warren. Be...          1\n",
       "3      This is easily the most underrated film inn th...          1\n",
       "4      This is not the typical Mel Brooks film. It wa...          1\n",
       "...                                                  ...        ...\n",
       "25000  I went and saw this movie last night after bei...          1\n",
       "25001  Actor turned director Bill Paxton follows up h...          1\n",
       "25002  As a recreational golfer with some knowledge o...          1\n",
       "25003  I saw this film in a sneak preview, and it is ...          1\n",
       "25004  Bill Paxton has taken the true story of the 19...          1\n",
       "\n",
       "[25005 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(25005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[0:25000].to_csv(\"./movie_reviews_train_data.csv\", index=False)\n",
    "dataframe[25000:50000].to_csv(\"./movie_reviews_test_data.csv\", index=False)\n",
    "dataframe.to_csv(\"./movie_reviews_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the train csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('movie_reviews_train_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the data\n",
    "The extrated data is sorted in order, we can not trian the ordered datset. Here, we will shuffle the above sorted dataset using permutation function from the np.random submodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "#train_data = train_data.reindex(np.random.permutation(train_data.index))\n",
    "# Another way\n",
    "#train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...          1\n",
       "1  Homelessness (or Houselessness as George Carli...          1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...          1\n",
       "3  This is easily the most underrated film inn th...          1\n",
       "4  This is not the typical Mel Brooks film. It wa...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and removing the unwanted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing line break> tags \n",
    "train_data['review'] = train_data['review'].str.replace('<br />','')\n",
    "#Removing Numbers\n",
    "train_data['review'] = train_data['review'].str.replace('\\d+', '')\n",
    "#Removing -- character\n",
    "train_data['review'] = train_data['review'].str.replace(\"--\", '')\n",
    "#Removing Punctuations\n",
    "train_data['review'] = train_data['review'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "    print(raw_review)\n",
    "    \n",
    "    # 1. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review) \n",
    "    print(\"\\n\")\n",
    "    print(letters_only)\n",
    "    \n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    print(\"\\n\")\n",
    "    print(words)\n",
    "    \n",
    "    # 3. In Python, searching a set is much faster than searching a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # 4. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops] \n",
    "    print(\"\\n\")\n",
    "    print(meaningful_words)\n",
    "    \n",
    "    # 5. Stemming\n",
    "    words = [stemmer.stem(word) for word in meaningful_words]\n",
    "    print(\"\\n\")\n",
    "    print(words)\n",
    "    # and return the result.\n",
    "    \n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy It ran at the same time as some other programs about school life such as Teachers My  years in the teaching profession lead me to believe that Bromwell Highs satire is much closer to reality than is Teachers The scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools I knew and their students When I saw the episode in which a student repeatedly tried to burn down the school I immediately recalled  at  High A classic line INSPECTOR Im here to sack one of your teachers STUDENT Welcome to Bromwell High I expect that many adults of my age think that Bromwell High is far fetched What a pity that it isnt\n",
      "\n",
      "\n",
      "Bromwell High is a cartoon comedy It ran at the same time as some other programs about school life such as Teachers My  years in the teaching profession lead me to believe that Bromwell Highs satire is much closer to reality than is Teachers The scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools I knew and their students When I saw the episode in which a student repeatedly tried to burn down the school I immediately recalled  at  High A classic line INSPECTOR Im here to sack one of your teachers STUDENT Welcome to Bromwell High I expect that many adults of my age think that Bromwell High is far fetched What a pity that it isnt\n",
      "\n",
      "\n",
      "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', 'such', 'as', 'teachers', 'my', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bromwell', 'highs', 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', 'teachers', 'the', 'scramble', 'to', 'survive', 'financially', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', 'pomp', 'the', 'pettiness', 'of', 'the', 'whole', 'situation', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', 'i', 'immediately', 'recalled', 'at', 'high', 'a', 'classic', 'line', 'inspector', 'im', 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers', 'student', 'welcome', 'to', 'bromwell', 'high', 'i', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'bromwell', 'high', 'is', 'far', 'fetched', 'what', 'a', 'pity', 'that', 'it', 'isnt']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['bromwell', 'high', 'cartoon', 'comedy', 'ran', 'time', 'programs', 'school', 'life', 'teachers', 'years', 'teaching', 'profession', 'lead', 'believe', 'bromwell', 'highs', 'satire', 'much', 'closer', 'reality', 'teachers', 'scramble', 'survive', 'financially', 'insightful', 'students', 'see', 'right', 'pathetic', 'teachers', 'pomp', 'pettiness', 'whole', 'situation', 'remind', 'schools', 'knew', 'students', 'saw', 'episode', 'student', 'repeatedly', 'tried', 'burn', 'school', 'immediately', 'recalled', 'high', 'classic', 'line', 'inspector', 'im', 'sack', 'one', 'teachers', 'student', 'welcome', 'bromwell', 'high', 'expect', 'many', 'adults', 'age', 'think', 'bromwell', 'high', 'far', 'fetched', 'pity', 'isnt']\n",
      "\n",
      "\n",
      "['bromwel', 'high', 'cartoon', 'comedi', 'ran', 'time', 'program', 'school', 'life', 'teacher', 'year', 'teach', 'profess', 'lead', 'believ', 'bromwel', 'high', 'satir', 'much', 'closer', 'realiti', 'teacher', 'scrambl', 'surviv', 'financi', 'insight', 'student', 'see', 'right', 'pathet', 'teacher', 'pomp', 'petti', 'whole', 'situat', 'remind', 'school', 'knew', 'student', 'saw', 'episod', 'student', 'repeatedli', 'tri', 'burn', 'school', 'immedi', 'recal', 'high', 'classic', 'line', 'inspector', 'im', 'sack', 'one', 'teacher', 'student', 'welcom', 'bromwel', 'high', 'expect', 'mani', 'adult', 'age', 'think', 'bromwel', 'high', 'far', 'fetch', 'piti', 'isnt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bromwel high cartoon comedi ran time program school life teacher year teach profess lead believ bromwel high satir much closer realiti teacher scrambl surviv financi insight student see right pathet teacher pomp petti whole situat remind school knew student saw episod student repeatedli tri burn school immedi recal high classic line inspector im sack one teacher student welcom bromwel high expect mani adult age think bromwel high far fetch piti isnt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_words(train_data.review[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why to use only CountVectorizer\n",
    "* The TfidfTransformer transforms a count matrix to a normalized tf or tf-idf representation. So although both the CountVectorizer and TfidfTransformer (with use_idf=False) produce term frequencies, TfidfTransformer is normalizing the count.\n",
    "\n",
    "Ref - https://www.quora.com/What-is-the-difference-between-TfidfVectorizer-and-CountVectorizer-1\n",
    "\n",
    "Ref - https://stackoverflow.com/questions/35867484/pass-tokens-to-countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#cv = CountVectorizer()\n",
    "#cv = CountVectorizer(stop_words='english')\n",
    "cv = CountVectorizer(stop_words = 'english', lowercase = True, decode_error = 'ignore',min_df=0.01, max_df=0.99)\n",
    "tdm = cv.fit_transform(train_data.review)\n",
    "#type(tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1478"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of words in the dictionary\n",
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dictionary length varies based on the parameters we give CountVectorizer:\n",
    "* CountVectorizer() --> 1,38,141 words\n",
    "* CountVectorizer(stop_words='english') --> 1,37,831 words\n",
    "* CountVectorizer(stop_words='english', min_df=0.01, max_df=0.99) --> 1,478 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ability', 'able', 'absolute', 'absolutely', 'absurd', 'academy', 'accent', 'accept', 'accident', 'according', 'accurate', 'act', 'acted', 'acting', 'action', 'actions', 'actor', 'actors', 'actress', 'actresses', 'acts', 'actual', 'actually', 'adaptation', 'add', 'added', 'addition', 'adds', 'admit', 'adult', 'adults', 'adventure', 'affair', 'afraid', 'age', 'agent', 'ago', 'agree', 'ahead', 'air', 'alive', 'allow', 'allowed', 'amazing', 'america', 'american', 'americans', 'amusing', 'angry', 'animal', 'animals', 'animated', 'animation', 'annoying', 'answer', 'anybody', 'anymore', 'apart', 'apparent', 'apparently', 'appeal', 'appear', 'appearance', 'appeared', 'appears', 'appreciate', 'approach', 'area', 'arent', 'army', 'art', 'artist', 'artistic', 'aside', 'ask', 'asked', 'asks', 'aspect', 'aspects', 'atmosphere', 'attack', 'attempt', 'attempts', 'attention', 'attractive', 'audience', 'audiences', 'available', 'average', 'avoid', 'award', 'aware', 'away', 'awesome', 'awful', 'baby', 'background', 'bad', 'badly', 'band', 'bar', 'barely', 'based', 'basic', 'basically', 'battle', 'beat', 'beautiful', 'beautifully', 'beauty', 'bed', 'began', 'begin', 'beginning', 'begins', 'believable', 'believe', 'ben', 'best', 'better', 'big', 'biggest', 'billy', 'bit', 'bits', 'bizarre', 'black', 'blame', 'blood', 'bloody', 'blue', 'body', 'book', 'books', 'bored', 'boring', 'born', 'boss', 'bother', 'bought', 'box', 'boy', 'boyfriend', 'boys', 'brain', 'break', 'brief', 'brilliant', 'bring', 'brings', 'british', 'brother', 'brothers', 'brought', 'brutal', 'budget', 'build', 'building', 'bunch', 'business', 'buy', 'called', 'came', 'camera', 'camp', 'capture', 'car', 'care', 'career', 'carry', 'cartoon', 'case', 'cast', 'casting', 'cat', 'catch', 'caught', 'cause', 'central', 'century', 'certain', 'certainly', 'chance', 'change', 'changed', 'changes', 'channel', 'character', 'characters', 'charles', 'charm', 'charming', 'chase', 'cheap', 'check', 'cheesy', 'chemistry', 'child', 'childhood', 'children', 'choice', 'chris', 'christmas', 'christopher', 'church', 'cinema', 'cinematic', 'cinematography', 'city', 'class', 'classic', 'clear', 'clearly', 'clever', 'cliché', 'clichés', 'climax', 'close', 'clothes', 'club', 'cold', 'collection', 'college', 'color', 'come', 'comedic', 'comedies', 'comedy', 'comes', 'comic', 'coming', 'comment', 'commentary', 'comments', 'common', 'company', 'compare', 'compared', 'compelling', 'complete', 'completely', 'complex', 'computer', 'concept', 'conclusion', 'confused', 'confusing', 'consider', 'considered', 'considering', 'constant', 'constantly', 'contains', 'content', 'continue', 'control', 'convincing', 'cool', 'cop', 'copy', 'costumes', 'count', 'country', 'couple', 'course', 'cover', 'crap', 'crazy', 'create', 'created', 'creating', 'creative', 'credit', 'credits', 'creepy', 'crew', 'crime', 'criminal', 'critics', 'cult', 'culture', 'cut', 'cute', 'dad', 'damn', 'dance', 'dancing', 'dangerous', 'dark', 'date', 'daughter', 'david', 'day', 'days', 'dead', 'deal', 'death', 'decent', 'decide', 'decided', 'decides', 'deep', 'deeply', 'definitely', 'deliver', 'delivers', 'depth', 'deserve', 'deserved', 'deserves', 'design', 'desire', 'desperate', 'despite', 'details', 'detective', 'developed', 'development', 'dialog', 'dialogue', 'did', 'didnt', 'die', 'died', 'dies', 'difference', 'different', 'difficult', 'direct', 'directed', 'directing', 'direction', 'director', 'directors', 'dirty', 'disappointed', 'disappointing', 'disappointment', 'disaster', 'discover', 'disney', 'disturbing', 'doctor', 'documentary', 'does', 'doesnt', 'dog', 'doing', 'dont', 'door', 'double', 'doubt', 'dr', 'drama', 'dramatic', 'drawn', 'dream', 'dreams', 'drive', 'drug', 'dull', 'dumb', 'dvd', 'dying', 'earlier', 'early', 'earth', 'easily', 'easy', 'edge', 'editing', 'effect', 'effective', 'effects', 'effort', 'element', 'elements', 'emotion', 'emotional', 'emotions', 'end', 'ended', 'ending', 'ends', 'energy', 'engaging', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'entertaining', 'entertainment', 'entire', 'entirely', 'epic', 'episode', 'episodes', 'equally', 'era', 'escape', 'especially', 'event', 'events', 'eventually', 'everybody', 'evil', 'exactly', 'example', 'excellent', 'exception', 'exciting', 'excuse', 'exist', 'expect', 'expectations', 'expected', 'expecting', 'experience', 'explain', 'explained', 'explanation', 'extra', 'extreme', 'extremely', 'eye', 'eyes', 'face', 'faces', 'fact', 'fail', 'failed', 'fails', 'fair', 'fairly', 'fake', 'fall', 'falling', 'falls', 'familiar', 'family', 'famous', 'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fascinating', 'fashion', 'fast', 'father', 'favorite', 'favourite', 'fear', 'feature', 'features', 'featuring', 'feel', 'feeling', 'feelings', 'feels', 'fell', 'fellow', 'felt', 'female', 'festival', 'fiction', 'fight', 'fighting', 'figure', 'filled', 'film', 'filmed', 'filming', 'filmmaker', 'filmmakers', 'filmmaking', 'films', 'final', 'finally', 'finding', 'finds', 'fine', 'finest', 'finish', 'finished', 'fit', 'flat', 'flaws', 'flick', 'flicks', 'flying', 'focus', 'folks', 'follow', 'followed', 'following', 'follows', 'food', 'footage', 'force', 'forced', 'forever', 'forget', 'forgotten', 'form', 'forward', 'frank', 'free', 'french', 'fresh', 'friend', 'friends', 'fully', 'fun', 'funniest', 'funny', 'future', 'game', 'gang', 'garbage', 'gave', 'gay', 'gem', 'general', 'generally', 'genius', 'genre', 'george', 'german', 'gets', 'getting', 'ghost', 'giant', 'girl', 'girlfriend', 'girls', 'given', 'gives', 'giving', 'glad', 'god', 'goes', 'going', 'gone', 'good', 'gore', 'gorgeous', 'got', 'gotten', 'government', 'grace', 'grade', 'great', 'greatest', 'green', 'ground', 'group', 'growing', 'guess', 'gun', 'guy', 'guys', 'hadnt', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happening', 'happens', 'happy', 'hard', 'hardly', 'hate', 'hated', 'havent', 'having', 'head', 'heads', 'hear', 'heard', 'heart', 'heavy', 'held', 'hell', 'help', 'helped', 'helps', 'hero', 'heroes', 'hes', 'hey', 'hidden', 'high', 'highly', 'hilarious', 'historical', 'history', 'hit', 'hits', 'hold', 'holds', 'holes', 'hollywood', 'home', 'honest', 'honestly', 'hope', 'hopes', 'hoping', 'horrible', 'horror', 'hospital', 'hot', 'hour', 'hours', 'house', 'huge', 'human', 'humor', 'humour', 'hurt', 'husband', 'id', 'idea', 'ideas', 'ii', 'ill', 'im', 'image', 'images', 'imagination', 'imagine', 'imdb', 'immediately', 'impact', 'important', 'impossible', 'impressed', 'impression', 'impressive', 'include', 'included', 'includes', 'including', 'incredible', 'incredibly', 'independent', 'indian', 'industry', 'information', 'innocent', 'inside', 'inspired', 'instance', 'instead', 'intelligence', 'intelligent', 'intended', 'intense', 'interested', 'interesting', 'intriguing', 'introduced', 'involved', 'involving', 'island', 'isnt', 'issues', 'italian', 'ive', 'jack', 'james', 'jane', 'japanese', 'jason', 'jim', 'job', 'joe', 'john', 'joke', 'jokes', 'jones', 'journey', 'joy', 'jump', 'just', 'justice', 'keeping', 'keeps', 'kept', 'key', 'kid', 'kids', 'kill', 'killed', 'killer', 'killing', 'kills', 'kind', 'kinda', 'king', 'knew', 'know', 'knowing', 'known', 'knows', 'la', 'lack', 'lacking', 'lacks', 'ladies', 'lady', 'lame', 'land', 'language', 'large', 'late', 'later', 'laugh', 'laughable', 'laughed', 'laughing', 'laughs', 'law', 'lead', 'leading', 'leads', 'learn', 'leave', 'leaves', 'leaving', 'led', 'lee', 'left', 'let', 'lets', 'level', 'lies', 'life', 'light', 'lighting', 'likable', 'like', 'liked', 'likely', 'likes', 'limited', 'line', 'lines', 'list', 'listen', 'literally', 'little', 'live', 'lived', 'lives', 'living', 'local', 'location', 'london', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'loose', 'lord', 'lose', 'lost', 'lot', 'lots', 'loud', 'love', 'loved', 'lovely', 'lover', 'lovers', 'loves', 'loving', 'low', 'mad', 'magic', 'main', 'mainly', 'major', 'make', 'makers', 'makes', 'makeup', 'making', 'male', 'man', 'manage', 'managed', 'manages', 'manner', 'mans', 'mark', 'marriage', 'married', 'martin', 'mary', 'master', 'masterpiece', 'match', 'material', 'matter', 'maybe', 'mean', 'meaning', 'means', 'meant', 'mediocre', 'meet', 'meets', 'member', 'members', 'memorable', 'memory', 'men', 'mental', 'mention', 'mentioned', 'merely', 'mess', 'message', 'met', 'michael', 'middle', 'military', 'million', 'mind', 'minor', 'minute', 'minutes', 'miss', 'missed', 'missing', 'mistake', 'mix', 'modern', 'mom', 'moment', 'moments', 'money', 'monster', 'months', 'mood', 'moral', 'mother', 'motion', 'mouth', 'moved', 'moves', 'movie', 'movies', 'moving', 'mr', 'ms', 'murder', 'murders', 'music', 'musical', 'mysterious', 'mystery', 'naked', 'named', 'names', 'narrative', 'nasty', 'natural', 'nature', 'near', 'nearly', 'necessary', 'need', 'needed', 'needs', 'negative', 'new', 'news', 'nice', 'nicely', 'night', 'normal', 'normally', 'note', 'notice', 'noticed', 'novel', 'nudity', 'number', 'numbers', 'numerous', 'obvious', 'obviously', 'odd', 'offer', 'offers', 'office', 'oh', 'ok', 'okay', 'old', 'older', 'ones', 'open', 'opening', 'opens', 'opinion', 'opportunity', 'opposite', 'order', 'original', 'originally', 'oscar', 'outside', 'outstanding', 'overall', 'pace', 'pacing', 'paid', 'pain', 'painful', 'parents', 'park', 'particular', 'particularly', 'parts', 'party', 'pass', 'passion', 'past', 'pathetic', 'paul', 'pay', 'people', 'perfect', 'perfectly', 'performance', 'performances', 'period', 'person', 'personal', 'personality', 'personally', 'peter', 'phone', 'photography', 'physical', 'pick', 'picked', 'picture', 'pictures', 'piece', 'pieces', 'place', 'places', 'plain', 'plan', 'planet', 'play', 'played', 'players', 'playing', 'plays', 'pleasure', 'plenty', 'plot', 'plus', 'point', 'pointless', 'points', 'police', 'political', 'poor', 'poorly', 'popular', 'porn', 'portray', 'portrayal', 'portrayed', 'positive', 'possible', 'possibly', 'potential', 'power', 'powerful', 'predictable', 'premise', 'presence', 'present', 'presented', 'pretty', 'previous', 'prison', 'probably', 'problem', 'problems', 'process', 'produced', 'producer', 'producers', 'production', 'professional', 'project', 'prove', 'proves', 'provide', 'provides', 'public', 'pull', 'pulled', 'pure', 'purpose', 'puts', 'putting', 'quality', 'question', 'questions', 'quick', 'quickly', 'quiet', 'quite', 'race', 'random', 'rare', 'rarely', 'rate', 'rated', 'rating', 'ray', 'read', 'reading', 'ready', 'real', 'realistic', 'reality', 'realize', 'realized', 'really', 'reason', 'reasons', 'recent', 'recently', 'recommend', 'recommended', 'record', 'red', 'redeeming', 'relationship', 'relationships', 'release', 'released', 'remains', 'remake', 'remarkable', 'remember', 'reminded', 'reminds', 'rent', 'rented', 'respect', 'responsible', 'rest', 'result', 'return', 'returns', 'revenge', 'review', 'reviewers', 'reviews', 'rich', 'richard', 'ride', 'ridiculous', 'right', 'road', 'robert', 'rock', 'role', 'roles', 'roll', 'romance', 'romantic', 'room', 'run', 'running', 'runs', 'sad', 'sadly', 'said', 'sam', 'sat', 'save', 'saved', 'saw', 'say', 'saying', 'says', 'scared', 'scary', 'scene', 'scenery', 'scenes', 'school', 'science', 'scifi', 'score', 'scott', 'screen', 'screenplay', 'script', 'search', 'season', 'second', 'seconds', 'secret', 'seeing', 'seemingly', 'seen', 'sees', 'self', 'sense', 'sent', 'sequel', 'sequence', 'sequences', 'serial', 'series', 'seriously', 'set', 'sets', 'setting', 'sex', 'sexual', 'sexy', 'shame', 'share', 'shes', 'shock', 'shocking', 'shoot', 'shooting', 'short', 'shot', 'shots', 'shouldnt', 'showed', 'showing', 'shown', 'shows', 'sick', 'sight', 'silent', 'silly', 'similar', 'simple', 'simply', 'singing', 'single', 'sister', 'sit', 'sitting', 'situation', 'situations', 'slasher', 'sleep', 'slightly', 'slow', 'slowly', 'small', 'smart', 'smile', 'smith', 'social', 'society', 'soldiers', 'solid', 'somebody', 'somewhat', 'son', 'song', 'songs', 'soon', 'sorry', 'sort', 'soul', 'sound', 'sounds', 'soundtrack', 'south', 'space', 'speak', 'speaking', 'special', 'spend', 'spent', 'spirit', 'spoiler', 'spoilers', 'spot', 'st', 'stage', 'stand', 'standard', 'standards', 'stands', 'star', 'starring', 'stars', 'start', 'started', 'starting', 'starts', 'state', 'states', 'station', 'stay', 'step', 'stephen', 'steve', 'stick', 'stop', 'store', 'stories', 'story', 'storyline', 'straight', 'strange', 'street', 'strong', 'struggle', 'stuck', 'student', 'students', 'studio', 'stuff', 'stunning', 'stupid', 'style', 'subject', 'subtle', 'success', 'successful', 'suddenly', 'suggest', 'suicide', 'summer', 'super', 'superb', 'superior', 'support', 'supporting', 'suppose', 'supposed', 'supposedly', 'sure', 'surely', 'surprise', 'surprised', 'surprising', 'surprisingly', 'suspect', 'suspense', 'sweet', 'taken', 'takes', 'taking', 'tale', 'talent', 'talented', 'talk', 'talking', 'taste', 'team', 'tears', 'technical', 'teenage', 'television', 'tell', 'telling', 'tells', 'tension', 'terms', 'terrible', 'terribly', 'terrific', 'th', 'thank', 'thanks', 'thats', 'theater', 'theatre', 'theme', 'themes', 'theres', 'theyre', 'thing', 'things', 'think', 'thinking', 'thinks', 'thoroughly', 'thought', 'thriller', 'throw', 'thrown', 'time', 'times', 'tired', 'title', 'today', 'todays', 'told', 'tom', 'tone', 'tony', 'took', 'total', 'totally', 'touch', 'touching', 'tough', 'town', 'track', 'tragedy', 'tragic', 'trailer', 'train', 'trash', 'treat', 'treated', 'tried', 'tries', 'trip', 'trouble', 'true', 'truly', 'trust', 'truth', 'try', 'trying', 'turn', 'turned', 'turning', 'turns', 'tv', 'twice', 'twist', 'twists', 'type', 'typical', 'ugly', 'ultimately', 'unbelievable', 'understand', 'understanding', 'unfortunately', 'unique', 'unknown', 'unless', 'unlike', 'unnecessary', 'unusual', 'use', 'used', 'uses', 'using', 'usual', 'usually', 'utterly', 'value', 'values', 'van', 'various', 'version', 'victim', 'victims', 'video', 'view', 'viewer', 'viewers', 'viewing', 'villain', 'violence', 'violent', 'vision', 'visual', 'voice', 'wait', 'waiting', 'walk', 'walking', 'wall', 'want', 'wanted', 'wanting', 'wants', 'war', 'warning', 'wasnt', 'waste', 'wasted', 'watch', 'watchable', 'watched', 'watching', 'water', 'way', 'ways', 'weak', 'wearing', 'week', 'weird', 'went', 'werent', 'west', 'western', 'whats', 'whatsoever', 'white', 'whos', 'wife', 'wild', 'william', 'willing', 'win', 'winning', 'wish', 'witty', 'woman', 'women', 'won', 'wonder', 'wonderful', 'wonderfully', 'wondering', 'wont', 'wooden', 'woods', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worse', 'worst', 'worth', 'worthy', 'wouldnt', 'wow', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrote', 'yeah', 'year', 'years', 'yes', 'york', 'youd', 'youll', 'young', 'younger', 'youre', 'youve', 'zero', 'zombie', 'zombies']\n"
     ]
    }
   ],
   "source": [
    "# Print out the dictionary\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 2, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix = tdm.todense()\n",
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1478)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1468</th>\n",
       "      <th>1469</th>\n",
       "      <th>1470</th>\n",
       "      <th>1471</th>\n",
       "      <th>1472</th>\n",
       "      <th>1473</th>\n",
       "      <th>1474</th>\n",
       "      <th>1475</th>\n",
       "      <th>1476</th>\n",
       "      <th>1477</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  1468  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   1469  1470  1471  1472  1473  1474  1475  1476  1477  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1478 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix = pd.DataFrame(Matrix)\n",
    "Matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix['sentiment'] = train_data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1469</th>\n",
       "      <th>1470</th>\n",
       "      <th>1471</th>\n",
       "      <th>1472</th>\n",
       "      <th>1473</th>\n",
       "      <th>1474</th>\n",
       "      <th>1475</th>\n",
       "      <th>1476</th>\n",
       "      <th>1477</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  1469  1470  1471  1472  1473  1474  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     1     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   1475  1476  1477  sentiment  \n",
       "0     0     0     0          1  \n",
       "1     0     0     0          1  \n",
       "2     0     0     0          1  \n",
       "3     0     0     0          1  \n",
       "4     0     0     0          1  \n",
       "\n",
       "[5 rows x 1479 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1479)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y= Matrix[\"sentiment\"]\n",
    "X= Matrix.drop(['sentiment'],axis=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25,random_state=456)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750, 1478)\n",
      "(6250, 1478)\n",
      "(18750,)\n",
      "(6250,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-1 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver=\"lbfgs\", max_iter=500)\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=logreg.predict(X_train)\n",
    "y_val_pred=logreg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8338 1048]\n",
      " [ 915 8449]]\n",
      "\n",
      "\n",
      "[[2635  479]\n",
      " [ 477 2659]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_train,y_train_pred))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_val,y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Train Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      9386\n",
      "           1       0.89      0.90      0.90      9364\n",
      "\n",
      "    accuracy                           0.90     18750\n",
      "   macro avg       0.90      0.90      0.90     18750\n",
      "weighted avg       0.90      0.90      0.90     18750\n",
      "\n",
      "\n",
      "\n",
      "Classification Report on Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      3114\n",
      "           1       0.85      0.85      0.85      3136\n",
      "\n",
      "    accuracy                           0.85      6250\n",
      "   macro avg       0.85      0.85      0.85      6250\n",
      "weighted avg       0.85      0.85      0.85      6250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report on Train Data\")\n",
    "print(classification_report(y_train,y_train_pred,digits=2))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Classification Report on Test Data\")\n",
    "print(classification_report(y_val,y_val_pred,digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-2 MultinominalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes **(MultinomialNB)** The multinomial naive Bayes model is typically used for discrete counts. E.g., if we have a **text classification problem**, we can take the idea of bernoulli trials one step further and instead of **\"word occurs in the document\"** we have \"count how often word occurs in the document\", you can think of it as \"number of times outcome number x_i is observed over the n trials\"\n",
    "\n",
    "The Complement Naive Bayes **(Complement NB)** classifier was designed to correct the “severe assumptions” made by the standard Multinomial Naive Bayes classifier. It is particularly suited for **imbalanced data sets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**__Why Naive Bayes?__**\n",
    "1. Works well when there are more Data Points, few features\n",
    "2. Faster to predict\n",
    "3. Works well for multiclass problems\n",
    "4. Works well for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7811 1575]\n",
      " [1464 7900]]\n",
      "[[2546  568]\n",
      " [ 550 2586]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# Predictions on train data\n",
    "y_pred1=classifier.predict(X_train)\n",
    "print(confusion_matrix(y_train,y_pred1))\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred2=classifier.predict(X_val)\n",
    "print(confusion_matrix(y_val,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Train Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      9386\n",
      "           1       0.83      0.84      0.84      9364\n",
      "\n",
      "    accuracy                           0.84     18750\n",
      "   macro avg       0.84      0.84      0.84     18750\n",
      "weighted avg       0.84      0.84      0.84     18750\n",
      "\n",
      "\n",
      "\n",
      "Classification Report on Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      3114\n",
      "           1       0.82      0.82      0.82      3136\n",
      "\n",
      "    accuracy                           0.82      6250\n",
      "   macro avg       0.82      0.82      0.82      6250\n",
      "weighted avg       0.82      0.82      0.82      6250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report on Train Data\")\n",
    "print(classification_report(y_train,y_pred1,digits=2))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Classification Report on Test Data\")\n",
    "print(classification_report(y_val,y_pred2,digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-3 LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8264 1122]\n",
      " [ 926 8438]]\n",
      "\n",
      "\n",
      "[[2630  484]\n",
      " [ 422 2714]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "logreg_cv = LogisticRegressionCV(cv=5, solver=\"lbfgs\", max_iter=500)\n",
    "\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "# Predictions on train data\n",
    "y_pred3=logreg_cv.predict(X_train)\n",
    "print(confusion_matrix(y_train,y_pred3))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred4=logreg_cv.predict(X_val)\n",
    "print(confusion_matrix(y_val,y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Train Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      9386\n",
      "           1       0.88      0.90      0.89      9364\n",
      "\n",
      "    accuracy                           0.89     18750\n",
      "   macro avg       0.89      0.89      0.89     18750\n",
      "weighted avg       0.89      0.89      0.89     18750\n",
      "\n",
      "\n",
      "\n",
      "Classification Report on Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      3114\n",
      "           1       0.85      0.87      0.86      3136\n",
      "\n",
      "    accuracy                           0.86      6250\n",
      "   macro avg       0.86      0.86      0.86      6250\n",
      "weighted avg       0.86      0.86      0.86      6250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report on Train Data\")\n",
    "print(classification_report(y_train,y_pred3,digits=2))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Classification Report on Test Data\")\n",
    "print(classification_report(y_val,y_pred4,digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-4 LogisticRegression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=500, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\"C\": np.arange(0.1, 1, 0.1)}\n",
    "grid = GridSearchCV(logreg, parameters, cv=5)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "topC = grid.best_params_[\"C\"]\n",
    "print(topC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_1=grid.predict(X_train)\n",
    "y_val_pred_2=grid.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8310 1076]\n",
      " [ 917 8447]]\n",
      "\n",
      "\n",
      "[[2633  481]\n",
      " [ 446 2690]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_train,y_train_pred_1))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_val,y_val_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Train Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      9386\n",
      "           1       0.89      0.90      0.89      9364\n",
      "\n",
      "    accuracy                           0.89     18750\n",
      "   macro avg       0.89      0.89      0.89     18750\n",
      "weighted avg       0.89      0.89      0.89     18750\n",
      "\n",
      "\n",
      "\n",
      "Classification Report on Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85      3114\n",
      "           1       0.85      0.86      0.85      3136\n",
      "\n",
      "    accuracy                           0.85      6250\n",
      "   macro avg       0.85      0.85      0.85      6250\n",
      "weighted avg       0.85      0.85      0.85      6250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report on Train Data\")\n",
    "print(classification_report(y_train,y_train_pred_1,digits=2))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Classification Report on Test Data\")\n",
    "print(classification_report(y_val,y_val_pred_2,digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-5 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "# predict the labels on train dataset\n",
    "pred_train = rfc.predict(X_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "pred_val = rfc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9355   31]\n",
      " [ 121 9243]]\n",
      "\n",
      "\n",
      "[[2585  529]\n",
      " [ 976 2160]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train,pred_train))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_val,pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Train Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      9386\n",
      "           1       1.00      0.99      0.99      9364\n",
      "\n",
      "    accuracy                           0.99     18750\n",
      "   macro avg       0.99      0.99      0.99     18750\n",
      "weighted avg       0.99      0.99      0.99     18750\n",
      "\n",
      "\n",
      "\n",
      "Classification Report on Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.77      3114\n",
      "           1       0.80      0.69      0.74      3136\n",
      "\n",
      "    accuracy                           0.76      6250\n",
      "   macro avg       0.76      0.76      0.76      6250\n",
      "weighted avg       0.76      0.76      0.76      6250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report on Train Data\")\n",
    "print(classification_report(y_train,pred_train,digits=2))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Classification Report on Test Data\")\n",
    "print(classification_report(y_val,pred_val,digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
